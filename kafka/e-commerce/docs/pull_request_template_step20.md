# Chapter. 4 장애대응


### **`STEP 20`**

- 위 테스트를 진행하며 획득한 다양한 성능 지표를 분석 및 시스템 내의 병목을 탐색 및 개선해보고 **(가상)** 장애 대응 문서를 작성하고 제출
- 최종 발표 자료 작성 및 제출
-----------------------------------------------------------------------------------------------------------------
## 🔍 부하 테스트 후 도출한 문제점 및 개선안 보고서 


### 문제점 1: 초기 급격한 부하 시 성능 하락
 - 현상: Spike 시나리오에서 VU가 급증(0 → 1000)할 때 응답 시간이 일시적으로 크게 증가 (p95: 333ms)

 - 원인 분석:

    - Kafka 메시지 큐 처리 지연 → 컨슈머가 메시지를 실시간으로 처리하지 못해 대기열 증가
    - DB 커넥션 풀, Redis 요청 동시처리 한계

 - 개선안:

   - Kafka 컨슈머 수(horizontal scale) 조정 또는 파티셔닝 확대
   - MySQL/HikariCP 커넥션 풀 크기 동적 조정
   - Redis에 대한 요청 캐싱 전략 조정 (예: 조회수 증가 로직을 local-queue + bulk update 방식으로 전환)


### 문제점 2: 애플리케이션 오류 감지 부족
- 현상: HTTP 4xx/5xx 오류가 발생해도 서비스 내부에서 적절한 로그가 남지 않아, 실제 운영 시 실패율이나 오류 원인 분석이 어려움.
- 원인 분석:
  - k6 스크립트에는 check() 함수나 http_req_failed 트래킹이 빠져 있음.
  - 백엔드 서비스에서는 예외 발생 시 상태코드만 반환하고, 실제 에러 로그 기록이나 모니터링 이벤트 발행이 누락됨.

- 개선안:
   - 서비스 개선안 : 모든 API 응답에 대해 4xx, 5xx 오류 발생 시 → 서비스 로그에 명확한 메시지 기록 (요청 정보, 에러 원인, 유저 ID 등 포함).
   - 오류 응답 시에도 일관된 에러 응답 포맷 사용 (code, message, traceId 포함).
   - 기타 알림 시스템 연동 : 오류 발생 시, 특정 조건(예: 5xx 응답, 시스템 예외 발생 등)에 따라 Slack 채널로 알림 전송
   - Prometheus, Grafana, Sentry 등 연동하여 5xx/4xx 에러 메트릭을 수집 → 
에러 임계치 초과 시 알림 발생하도록 설정 가능


### 문제점 3: 인기 상품 조회 부하 집중
- 현상: /popularProduct/today API에 조회 요청 집중 → Redis 부하
- 원인 분석:
  - 조회수 증가를 요청마다 ZSET 반영
- 개선안:
  - local queue로 수집 후 일정 주기마다 batch update
  - 인기 상품은 Redis에 캐시된 Top-N만 제공 → TTL 기반 자동 리프레시

-----------------------------------------------------------------------------------------------------------------

